{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import model_utils\n",
    "\n",
    "from pickle import load\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Model\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from numpy import argmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_for_id(integer, tokenizer):\n",
    "    for word, index in tokenizer.word_index.items():\n",
    "        if index == integer:\n",
    "            return word\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_desc(model, tokenizer, photo, max_length):\n",
    "    in_text = 'startseq'\n",
    "    for i in range(max_length):\n",
    "        sequence = tokenizer.texts_to_sequences([in_text])[0]\n",
    "        sequence = pad_sequences([sequence], maxlen=max_length)\n",
    "        yhat = model.predict([photo,sequence], verbose=0)\n",
    "        yhat = argmax(yhat)\n",
    "        word = word_for_id(yhat, tokenizer)\n",
    "        if word is None:\n",
    "            break\n",
    "        in_text += ' ' + word\n",
    "        if word == 'endseq':\n",
    "            break\n",
    "    return in_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initiate_encoder(arch='capsnet'):\n",
    "    if arch=='capsnet':\n",
    "        encoder_model = model_utils.load_DeepCapsNet(input_shape=(64,64,3), n_class=10, routings=3, \\\n",
    "                        weights=r'D:\\CapsuleNetwork_ImageCaptioning\\Flickr8k_image_captioning_using_CapsNet\\weights\\deep_caps_best_weights.h5')\n",
    "    else:\n",
    "        encoder_model = model_utils.load_VGG()\n",
    "    return encoder_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_feature(model, arch, image_path):\n",
    "    feature = None\n",
    "    model = Model(inputs=model.inputs, outputs=model.layers[-1].output)\n",
    "    target_size = (64,64) if arch=='capsnet' else (224,224)\n",
    "    try:\n",
    "        image = load_img(image_path, target_size=target_size)\n",
    "    except Exception as e:\n",
    "        print('{} could not be opened. Skipping\\n {}'.format(image_path,e))\n",
    "        return None\n",
    "    image = img_to_array(image)\n",
    "    image = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))\n",
    "    if arch=='capsnet':\n",
    "        feature = model.predict(image, verbose=0).reshape(-1, 10*32)\n",
    "    else:\n",
    "        image = preprocess_input(image)\n",
    "        feature = model.predict(image, verbose=0)\n",
    "    return feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoder_model = initiate_encoder(arch='capsnet')\n",
    "photo_feature = extract_feature(encoder_model, 'capsnet', r'C:\\Users\\jayde\\OneDrive\\Desktop\\man.jpg')\n",
    "max_length = 34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "startseq hiviz while baby the wind background one sits horse the flames the bags the ready rocky the snowboarders violin thumbs the book player white stands jumps the the position the both horse the the\n"
     ]
    }
   ],
   "source": [
    "tokenizer = load(open('tokenizer.pkl', 'rb'))\n",
    "test_model = load_model(r'weights\\decoder_weights_ep60.h5')\n",
    "print(generate_desc(test_model, tokenizer, photo_feature, max_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "keras_tf_gpu",
   "language": "python",
   "name": "keras_tf_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
